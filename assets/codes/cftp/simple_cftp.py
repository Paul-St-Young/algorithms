"""
A simple, inefficient CFTP algorithm that
checks that all states coalesce by brute-force.

@author: Eli
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rc('font', size=26)
matplotlib.rc('lines', linewidth=3)
matplotlib.rcParams['lines.markersize'] = 10 
matplotlib.rcParams['figure.figsize']   = (16,12)

np.random.seed(42)

num_states = 10

# Check if a set of chains have all coalesced.
# Note: make sure the last index of the chains
# has been set.
def coalesced(chains):
    return np.all(chains[:,-1] == chains[0,-1])

# Time evolve a bunch of Markov chains from the given initial states using
# the given random numbers.
def run_markov_chains_forward(mc_function, initial_states, num_time_steps, random_nums):
    num_states  = len(initial_states)
    
    chains      = np.zeros((num_states, num_time_steps), dtype=int)
    chains[:,0] = initial_states
    
    for time in range(1,num_time_steps):
        chains[:,time] = mc_function(chains[:,time-1], random_nums[:,time-1])
        
    return chains

# Generate num_samples samples from the Markov chain by 
# using samples drawn after num_steps.
def mcmc(mc_function, num_states, num_steps_per_sample, num_random_numbers_per_step, burn_in_time, num_samples):
    num_time_steps = burn_in_time + num_steps_per_sample * num_samples
    
    # Start at a random initial state.
    initial_states = np.random.randint(num_states, size=(1,))

    # Generate the random numbers used for the chain.
    random_nums = np.random.rand(num_random_numbers_per_step, num_time_steps-1)

    # Run the Markov chain and save each state generated.
    chains = run_markov_chains_forward(mc_function, initial_states, num_time_steps, random_nums)
    
    # Separate out the sampled states.
    sampled_states = chains[0, range(burn_in_time, num_time_steps, num_steps_per_sample)]
    
    return sampled_states

# Generate num_samples perfect samples from the Markov chain, 
# which is specified by the mc_function.
def cftp(mc_function, num_states, initial_num_time_steps, num_random_numbers_per_step, num_samples):
    # The states used to check coalescence.
    states         = np.arange(num_states)
    # The final samples generated by CFTP.
    sampled_states = np.zeros(num_samples, dtype=int)
    
    # For visualization and debugging, keep track of all chains
    # explored during the Markov chain sampling.
    chains_history_samples = []
    for sample in range(num_samples):
        
        num_time_steps = initial_num_time_steps
        random_nums    = np.random.rand(num_random_numbers_per_step, num_time_steps-1)
        chains         = run_markov_chains_forward(mc_function, states, num_time_steps, random_nums)
        
        chains_history = []
        chains_history.append(chains)
            
        while not coalesced(chains):
            old_num_time_steps = num_time_steps
            # Each time, double the previous number of time steps to consider.
            num_time_steps = 2 * old_num_time_steps
            # Make sure that the previous random numbers are reused.
            # For times further in the past that have not been considered yet, 
            # generate "new" random numbers.
            new_random_nums = np.random.rand(num_random_numbers_per_step, num_time_steps-old_num_time_steps)
            random_nums     = np.hstack((new_random_nums, random_nums))
            
            chains = run_markov_chains_forward(mc_function, states, num_time_steps, random_nums)
            
            chains_history.append(chains)
            
        # All chains should converge to the same state, so
        # you can just consider the first chain's converged state.
        sampled_states[sample] = chains[0,-1]
        
        chains_history_samples.append(chains_history)
        
    return (sampled_states, chains_history_samples)

# Plots the evolution of a set of Markov chains.
def plot_chains(chains, time_shift=0):
    num_chains     = int(chains.shape[0])
    num_time_steps = int(chains.shape[1])
    for chain in range(num_chains):
        plt.plot(np.arange(num_time_steps)-time_shift, chains[chain,:], 'k-', linewidth=2)
    plt.xlabel('time') 
    plt.ylabel('state')    
    plt.yticks([0, 8, 16])

# Plots a visualization of the Markov chains
# sampled during the CFTP algorithm.
def plot_chains_history(chains_history):
    num_chains_histories = len(chains_history)
    
    longest_num_time_steps = int(chains_history[-1].shape[1])
    
    plt.figure()
    for ind_ch in range(num_chains_histories):
        nskip = 5
        if ind_ch <= nskip: continue
        plt.subplot(num_chains_histories-nskip, 1, ind_ch-nskip)
        
        num_time_steps = int(chains_history[ind_ch].shape[1])
        plot_chains(chains_history[ind_ch], time_shift=num_time_steps-1)
        
        plt.xlim([-longest_num_time_steps, 0])
        
### SPECIFIC EXAMPLE MARKOV CHAIN ###
    
num_states                  = 20
initial_num_time_steps      = 1
num_random_numbers_per_step = 1
num_samples                 = 1
    
# The random function f(x,r) used by the Markov chain to evolve
# in time. x_t = f(x_{t-1}, r), where x_t is the state at time
# t and r is a set of random numbers.
def markovchain_function(state, random_variables):
    if random_variables[0] < 0.45:
        return np.minimum(state+1, num_states-1)
    elif random_variables[0] < 0.46:
        return state
    else:
        return np.maximum(state-1, 0)

# Run CFTP once.
num_samples = 1
(sampled_states, chains_history_samples) = cftp(markovchain_function, num_states, initial_num_time_steps, num_random_numbers_per_step, num_samples)

# Plot the results.
plot_chains_history(chains_history_samples[0])
plt.subplots_adjust(hspace=0)

plt.savefig('bruteforce_cftp_histories.png', dpi=200)

# Run CFTP many times to make a histogram of the stationary distribution.
num_samples = 100*num_states
(sampled_states_cftp, chains_history_samples) = cftp(markovchain_function, num_states, initial_num_time_steps, num_random_numbers_per_step, num_samples)

# Run MCMC many times to make a historgram of the stationary distribution.
#num_samples          = 100*num_states
num_steps_per_sample = 4
burn_in_time         = num_states
sampled_states_mcmc  = mcmc(markovchain_function, num_states, num_steps_per_sample, num_random_numbers_per_step, burn_in_time, num_samples)

# Compare the histograms
plt.figure()

hist_cftp = np.zeros(num_states)
hist_mcmc = np.zeros(num_states)
for sample in range(num_samples):
    hist_cftp[sampled_states_cftp[sample]] += 1.0/num_samples
    hist_mcmc[sampled_states_mcmc[sample]] += 1.0/num_samples

plt.errorbar(np.arange(num_states), hist_cftp, yerr=np.sqrt(hist_cftp/num_samples),  fmt='o-', label='CFTP')
plt.errorbar(np.arange(num_states), hist_mcmc, yerr=np.sqrt(hist_mcmc/num_samples), fmt='^--', label='MCMC, T={}'.format(num_steps_per_sample))

plt.ylim([0,np.max(np.concatenate((hist_cftp, hist_mcmc)))])
plt.xlabel('State')
plt.ylabel('Frequency')

plt.legend()

plt.savefig('histograms.png', dpi=200)

# Histogram the coallescence times.
coallescence_times = np.zeros(num_samples)
for sample in range(num_samples):
    chains_history    = chains_history_samples[sample]
    coallesced_chains = chains_history[-1]
    inds_coallesced   = np.where(coallesced_chains[0,:] == coallesced_chains[-1,:])[0]
    coallescence_time = int(coallesced_chains.shape[1]) # np.min(inds_coallesced)
    
    coallescence_times[sample] = coallescence_time

plt.figure()
plt.hist(np.log(coallescence_times)/np.log(2), bins=20)

plt.xlabel('$\\log2$(Coallescence time)')
plt.ylabel('Frequency')

plt.savefig('coallescencetimes.png', dpi=200)

# Compute the autocorrelation of a time series.
def autocorrelation(xs, max_lag=None):
    num_time_steps = len(xs)
    
    if max_lag is None:
        max_lag = num_time_steps//2
    
    autocorr = np.zeros(max_lag, dtype=float)
    for t0 in range(num_time_steps):
        for t in range(np.minimum(num_time_steps-t0, max_lag)):
            autocorr[t] += xs[t0] * xs[t0+t] / (num_time_steps - t)
            
    avg_autocorr = np.mean(autocorr)
                
    autocorr -= avg_autocorr
    autocorr /= autocorr[0]
    
    return autocorr

# Plot the auto correlation between successive samples.
autocorr_cftp = autocorrelation(sampled_states_cftp)
autocorr_mcmc = autocorrelation(sampled_states_mcmc)

plt.figure()

plt.plot(autocorr_cftp, 'o-', label='CFTP')
plt.plot(autocorr_mcmc, '^-', label='MCMC')

plt.legend()

plt.xlabel('Sample (at each step of algorithm)')
plt.ylabel('Autocorrelation')

plt.savefig('autocorrelation.png', dpi=200)

# Show the plots.
plt.show()
